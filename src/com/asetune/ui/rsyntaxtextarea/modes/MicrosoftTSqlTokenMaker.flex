/*
 * 2020-04-30
 *
 * MicrosoftTSqlTokenMaker.java - Scanner for SQL.
 *
 * Copyright (C) 2020 Goran Schwarz
 * Copyright (C) 2005 Robert Futrell
 * robert_futrell at users.sourceforge.net
 * http://fifesoft.com/rsyntaxtextarea
 *
 * Most of the Reserved Words and functions are grabbed from:
 * https://docs.microsoft.com/en-us/sql/t-sql/functions/functions?view=sql-server-ver15
 * and some from:
 * https://github.com/dbcli/mssql-cli/blob/master/mssqlcli/packages/mssqlliterals/sqlliterals.json
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA.
 */
package com.asetune.ui.rsyntaxtextarea.modes;

import java.io.*;
import javax.swing.text.Segment;

import org.fife.ui.rsyntaxtextarea.*;


/**
 * This class generates tokens representing a text stream as SQL.<p>
 *
 * This implementation was created using
 * <a href="http://www.jflex.de/">JFlex</a> 1.4.1; however, the generated file
 * was modified for performance.  Memory allocation needs to be almost
 * completely removed to be competitive with the handwritten lexers (subclasses
 * of <code>AbstractTokenMaker</code>, so this class has been modified so that
 * Strings are never allocated (via yytext()), and the scanner never has to
 * worry about refilling its buffer (needlessly copying chars around).
 * We can achieve this because RText always scans exactly 1 line of tokens at a
 * time, and hands the scanner this line as an array of characters (a Segment
 * really).  Since tokens contain pointers to char arrays instead of Strings
 * holding their contents, there is no need for allocating new memory for
 * Strings.<p>
 *
 * The actual algorithm generated for scanning has, of course, not been
 * modified.<p>
 *
 * If you wish to regenerate this file yourself, keep in mind the following:
 * <ul>
 *   <li>The generated SQLTokenMaker.java</code> file will contain two
 *       definitions of both <code>zzRefill</code> and <code>yyreset</code>.
 *       You should hand-delete the second of each definition (the ones
 *       generated by the lexer), as these generated methods modify the input
 *       buffer, which we'll never have to do.</li>
 *   <li>You should also change the declaration/definition of zzBuffer to NOT
 *       be initialized.  This is a needless memory allocation for us since we
 *       will be pointing the array somewhere else anyway.</li>
 *   <li>You should NOT call <code>yylex()</code> on the generated scanner
 *       directly; rather, you should use <code>getTokenList</code> as you would
 *       with any other <code>TokenMaker</code> instance.</li>
 * </ul>
 *
 * @author Robert Futrell
 * @version 0.5
 *
 */
%%

%public
%class MicrosoftTSqlTokenMaker
%extends AbstractJFlexTokenMaker
%unicode
%ignorecase
%type org.fife.ui.rsyntaxtextarea.Token


%{


	/**
	 * Constructor.  This must be here because JFlex does not generate a
	 * no-parameter constructor.
	 */
	public MicrosoftTSqlTokenMaker() {
		super();
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 */
	private void addToken(int tokenType) {
		addToken(zzStartRead, zzMarkedPos-1, tokenType);
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 */
	private void addToken(int start, int end, int tokenType) {
		int so = start + offsetShift;
		addToken(zzBuffer, start,end, tokenType, so);
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param array The character array.
	 * @param start The starting offset in the array.
	 * @param end The ending offset in the array.
	 * @param tokenType The token's type.
	 * @param startOffset The offset in the document at which this token
	 *                    occurs.
	 */
	@Override
	public void addToken(char[] array, int start, int end, int tokenType, int startOffset) {
		super.addToken(array, start,end, tokenType, startOffset);
		zzStartRead = zzMarkedPos;
	}


	/**
	 * Returns the text to place at the beginning and end of a
	 * line to "comment" it in a this programming language.
	 *
	 * @return The start and end strings to add to a line to "comment"
	 *         it out.
	 */
	@Override
//	public String[] getLineCommentStartAndEnd() {
	public String[] getLineCommentStartAndEnd(int languageIndex) {
		return new String[] { "--", null };
	}

	/**
	 * {@inheritDoc}
	 */
	@Override
	public boolean getMarkOccurrencesOfTokenType(int type) {
		return type==Token.FUNCTION || type==Token.VARIABLE || type==Token.IDENTIFIER;
	}

	/**
	 * Returns the first token in the linked list of tokens generated
	 * from <code>text</code>.  This method must be implemented by
	 * subclasses so they can correctly implement syntax highlighting.
	 *
	 * @param text The text from which to get tokens.
	 * @param initialTokenType The token type we should start with.
	 * @param startOffset The offset into the document at which
	 *        <code>text</code> starts.
	 * @return The first <code>Token</code> in a linked list representing
	 *         the syntax highlighted text.
	 */
	@Override
	public Token getTokenList(Segment text, int initialTokenType, int startOffset) {

		resetTokenList();
		this.offsetShift = -text.offset + startOffset;

		// Start off in the proper state.
		int state = Token.NULL;
		switch (initialTokenType) {
			case Token.LITERAL_STRING_DOUBLE_QUOTE:
				state = STRING;
				start = text.offset;
				break;
			case Token.LITERAL_CHAR:
				state = CHAR;
				start = text.offset;
				break;
			case Token.COMMENT_MULTILINE:
				state = MLC;
				start = text.offset;
				break;
			default:
				state = Token.NULL;
		}

		s = text;
		try {
			yyreset(zzReader);
			yybegin(state);
			return yylex();
		} catch (IOException ioe) {
			ioe.printStackTrace();
			return new TokenImpl();
		}

	}


	/**
	 * Refills the input buffer.
	 *
	 * @return      <code>true</code> if EOF was reached, otherwise
	 *              <code>false</code>.
	 */
	private boolean zzRefill() {
		return zzCurrentPos>=s.offset+s.count;
	}


	/**
	 * Resets the scanner to read from a new input stream.
	 * Does not close the old reader.
	 *
	 * All internal variables are reset, the old input stream 
	 * <b>cannot</b> be reused (internal buffer is discarded and lost).
	 * Lexical state is set to <tt>YY_INITIAL</tt>.
	 *
	 * @param reader   the new input stream 
	 */
	public final void yyreset(java.io.Reader reader) {
		// 's' has been updated.
		zzBuffer = s.array;
		/*
		 * We replaced the line below with the two below it because zzRefill
		 * no longer "refills" the buffer (since the way we do it, it's always
		 * "full" the first time through, since it points to the segment's
		 * array).  So, we assign zzEndRead here.
		 */
		//zzStartRead = zzEndRead = s.offset;
		zzStartRead = s.offset;
		zzEndRead = zzStartRead + s.count - 1;
//		zzCurrentPos = zzMarkedPos = zzPushbackPos = s.offset;
		zzCurrentPos = zzMarkedPos = s.offset;
		zzLexicalState = YYINITIAL;
		zzReader = reader;
		zzAtBOL  = true;
		zzAtEOF  = false;
	}


%}

LineTerminator	= ([\n])
Letter			= ([A-Za-z])
Digit			= ([0-9])
Whitespace		= ([ \t]+)

IdentifierStart	= ({Letter})
IdentifierPart	= ({IdentifierStart}|{Digit}|[_])
Identifier		= ({IdentifierStart}{IdentifierPart}*)
Variable		= (@{Identifier})
/*GlobalVariable	= (@@{Identifier})*/

Operator		= (">="|"<="|"<>"|">"|"<"|"="|"+"|"-"|"*"|"/")
Separator		= ([\(\)])

Parameter		= ([:]{Identifier})

Integer			= ({Digit}+)
Float			= (({Digit}+[.]{Digit}*)|([.]{Digit}*))
ApproxNum		= (({Digit}+[eE][+-]?{Digit}+)|({Digit}+[.]{Digit}*[eE][+-]?[0-9]+)|([.][0-9]*[eE][+-]?[0-9]+))

CommentBegin	= ("--")
Comment			= ({CommentBegin}.*)
MLCBegin		= "/*"
MLCEnd			= "*/"

%state STRING
%state CHAR
%state MLC

%%

<YYINITIAL> {

	/* Keywords */

	/*================================================
	** Microsoft Transact-SQL reserved words
	**================================================*/
		"ADD" | "ALL" | "ALTER" | "AND" | "ANY" | "AS" | "ASC" | "AUTHORIZATION"
		| "BACKUP" | "BEGIN" | "BETWEEN" | "BREAK" | "BROWSE" | "BULK" | "BY"
		| "CASCADE" | "CASE" | "CHECK" | "CHECKPOINT" | "CLOSE" | "CLUSTERED" | "COLLATE" | "COLUMN" | "COMMIT" | "COMPUTE" | "CONSTRAINT"  | "CONTAINS" | "CONTAINSTABLE" | "CONTINUE" | "CREATE" | "CROSS" | "CURRENT" | "CURSOR"
		| "DATABASE" | "DBCC" | "DEALLOCATE" | "DECLARE" | "DEFAULT" | "DELETE" | "DENY" | "DESC" | "DISK" | "DISTINCT" | "DISTRIBUTED" | "DROP" | "DUMP"
		| "ELSE" | "END" | "ERRLVL" | "ESCAPE" | "EXCEPT" | "EXEC" | "EXECUTE" | "EXISTS" | "EXIT" | "EXTERNAL"
		| "FETCH" | "FILE" | "FILLFACTOR" | "FOR" | "FOREIGN" | "FREETEXT" | "FREETEXTTABLE" | "FROM" | "FULL" | "FUNCTION"
		| "GOTO" | "GRANT" | "GROUP"
		| "HAVING" | "HOLDLOCK" 
		| "IDENTITY" | "IDENTITY_INSERT" | "IDENTITYCOL" | "IF" | "IN" | "INDEX" | "INNER" | "INSERT" | "INTERSECT" | "INTO" | "IS"
		| "JOIN"
		| "KEY" | "KILL"
		| "LEFT" | "LIKE" | "LINENO" | "LOAD"
		| "MERGE"
		| "NATIONAL" | "NOCHECK" | "NONCLUSTERED" | "NOT" | "NULL"
		| "OF" | "OFF" | "OFFSETS" | "ON" | "OPEN" | "OPTION" | "OR" | "ORDER" | "OUTER" | "OVER"
		| "PERCENT" | "PIVOT" | "PLAN" | "PRECISION" | "PRIMARY" | "PRINT" | "PROC" | "PROCEDURE" | "PUBLIC"
		| "RAISERROR" | "READ" | "READTEXT" | "RECONFIGURE" | "REFERENCES" | "REPLICATION" | "RESTORE" | "RESTRICT" | "RETURN" | "REVERT" | "REVOKE" | "RIGHT" | "ROLLBACK" | "ROWCOUNT" | "ROWGUIDCOL" | "RULE"
		| "SAVE" | "SCHEMA" | "SECURITYAUDIT" | "SELECT" | "SEMANTICKEYPHRASETABLE" | "SEMANTICSIMILARITYDETAILSTABLE" | "SEMANTICSIMILARITYTABLE" | "SET" | "SETUSER" | "SHUTDOWN" | "SOME" | "STATISTICS"
		| "TABLE" | "TABLESAMPLE" | "TEXTSIZE" | "THEN" | "TO" | "TOP" | "TRAN" | "TRANSFER" | "TRANSACTION" | "TRIGGER" | "TRUNCATE"
		| "UNION" | "UNIQUE" | "UNPIVOT" | "UPDATE" | "UPDATETEXT" | "USE" | "USER"
		| "VALUES" | "VARYING" | "VIEW"
		| "WAITFOR" | "WHEN" | "WHERE" | "WHILE" | "WITH" | "WITHIN GROUP" | "WRITETEXT"
		{ addToken(Token.RESERVED_WORD); }
		
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
			-- below is FUNCTIONS, which is marked in that section
		 	-- functions: "COALESCE" | "CONVERT" | "CURRENT_DATE" | "CURRENT_TIME" | "CURRENT_TIMESTAMP" | "CURRENT_USER" |  "NULLIF" 
			            | "OPENDATASOURCE" | "OPENQUERY" | "OPENROWSET" | "OPENXML" | "SESSION_USER" | "SYSTEM_USER" | "TRY_CONVERT" |  "TSEQUAL"
			-- datatypes: "DOUBLE" 
		 *------------------------------------------------*/
		 	-- functions: "COALESCE" | "NULLIF" | "TSEQUAL"

	/*================================================
	** Extra kewords added by Goran Schwarz
	** most found at: https://github.com/dbcli/mssql-cli/blob/master/mssqlcli/packages/mssqlliterals/sqlliterals.json
	** and the missing ones are "parameters" to ALTER, CREATE, DROP
	**================================================*/
		"apply" | "APPLICATION" | "ASSEMBLY" | "AVAILABILITY" | "AUDIT"
		| "BINDING" | "BROKER"
		| "CERTIFICATE" | "CONFIGURATION" | "CREDENTIAL" | "CRYPTOGRAPHIC"
		| "ENDPOINT" | "EVENT" | "ENCRYPTION"
		| "FULLTEXT"
		| "GOVERNOR"
		| "HADR"
		| "LIBRARY" | "LIST" | "LOGIN"
		| "MASTER" | "MESSAGE"
		| "POLICY" | "POOL" | "PRIORITY" | "PROPERTY" | "PROVIDER"
		| "QUEUE"
		| "REMOTE" | "RESOURCE" | "ROUTE"
		| "SCOPED" | "SERVICE" | "SECURITY" | "SERVER" | "SOURCE" | "SPECIFICATION" | "STOPLIST"
		| "TYPE"
		| "WORKLOAD"
		{ addToken(Token.RESERVED_WORD); }

	/*================================================
	** Microsoft Transact-SQL Possible reserved words in the future
	**================================================*/
		"ABSOLUTE" | "ACTION" | "ADMIN" | "AFTER" | "AGGREGATE" | "ALIAS" | "ALLOCATE" | "ARE" | "ARRAY" | "ASENSITIVE" | "ASSERTION" | "ASYMMETRIC" | "AT" | "ATOMIC"
		| "BEFORE" | "BINARY" | "BOTH" | "BREADTH"
		| "CALL" | "CALLED" | "CARDINALITY" | "CASCADED" | "CAST" | "CATALOG" | "CLASS" | "COLLATION" | "COLLECT" | "COMPLETION" | "CONDITION" | "CONNECT" | "CONNECTION" | "CONSTRAINTS" | "CONSTRUCTOR" | "CORR" | "CORRESPONDING" | "COVAR_POP" | "COVAR_SAMP" | "CUBE" | "CUME_DIST" | "CURRENT_DEFAULT_TRANSFORM_GROUP" | "CURRENT_TRANSFORM_GROUP_FOR_TYPE" | "CYCLE"
		| "DATA" | "DEFERRABLE" | "DEFERRED" | "DEPTH" | "DEREF" | "DESCRIBE" | "DESCRIPTOR" | "DESTROY" | "DESTRUCTOR" | "DETERMINISTIC" | "DICTIONARY" | "DIAGNOSTICS" | "DISCONNECT" | "DOMAIN" | "DYNAMIC"
		| "EACH" | "ELEMENT" | "END-EXEC" | "EQUALS" | "EVERY" | "EXCEPTION"
		| "FALSE" | "FILTER" | "FIRST" | "FOUND" | "FREE" | "FULLTEXTTABLE" | "FUSION"
		| "GENERAL" | "GET" | "GLOBAL" | "GROUPING"
		| "HOLD" | "HOST" 
		| "IGNORE" | "IMMEDIATE" | "INDICATOR" | "INITIALIZE" | "INITIALLY" | "INOUT" | "INPUT" | "INTERSECTION" | "INTERVAL" | "ISOLATION" | "ITERATE"
		| "LANGUAGE" | "LARGE" | "LAST" | "LATERAL" | "LEADING" | "LESS" | "LEVEL" | "LIKE_REGEX" | "LIMIT" | "LN" | "LOCAL" | "LOCATOR"
		| "MAP" | "MATCH" | "MEMBER" | "METHOD" | "MOD" | "MODIFIES" | "MODIFY" | "MODULE" | "MULTISET"
		| "NAMES" | "NATURAL" | "NEW" | "NEXT" | "NO" | "NONE" | "NORMALIZE"
		| "OBJECT" | "OCCURRENCES_REGEX" | "OLD" | "ONLY" | "OPERATION" | "ORDINALITY" | "OUT" | "OVERLAY" | "OUTPUT"
		| "PAD" | "PARAMETER" | "PARAMETERS" | "PARTIAL" | "PARTITION" | "PATH" | "POSTFIX" | "PREFIX" | "PREORDER" | "PREPARE" | "POSITION_REGEX" | "PRESERVE" | "PRIOR" | "PRIVILEGES"
		| "RANGE" | "READS" | "RECURSIVE" | "REF" | "REFERENCING" | "REGR_AVGX" | "REGR_AVGY" | "REGR_COUNT" | "REGR_INTERCEPT" | "REGR_R2" | "REGR_SLOPE" | "REGR_SXX" | "REGR_SXY" | "REGR_SYY" | "RELATIVE" | "RELEASE" | "RESULT" | "RETURNS" | "ROLE" | "ROLLUP" | "ROUTINE" | "ROW" | "ROWS"
		| "SAVEPOINT" | "SCROLL" | "SCOPE" | "SEARCH" | "SECTION" | "SENSITIVE" | "SEQUENCE" | "SESSION" | "SETS" | "SIMILAR" | "SIZE" | "SPACE" | "SPECIFIC" | "SPECIFICTYPE" | "SQL" | "SQLEXCEPTION" | "SQLSTATE" | "SQLWARNING" | "START" | "STATE" | "STATEMENT" | "STATIC" | "STRUCTURE" | "SUBMULTISET" | "SUBSTRING_REGEX" | "SYMMETRIC" | "SYSTEM"
		| "TEMPORARY" | "TERMINATE" | "THAN" | "TRAILING" | "TRANSLATE_REGEX" | "TRANSLATION" | "TREAT" | "TRUE"
		| "UESCAPE" | "UNDER" | "UNKNOWN" | "UNNEST" | "USAGE" | "USING"
		| "VALUE"
		| "WHENEVER" | "WIDTH_BUCKET" | "WITHOUT" | "WINDOW" | "WITHIN" | "WORK" | "WRITE"
		| "XMLAGG" | "XMLATTRIBUTES" | "XMLBINARY" | "XMLCAST" | "XMLCOMMENT" | "XMLCONCAT" | "XMLDOCUMENT" | "XMLELEMENT" | "XMLEXISTS" | "XMLFOREST" | "XMLITERATE" | "XMLNAMESPACES" | "XMLPARSE" | "XMLPI" | "XMLQUERY" | "XMLSERIALIZE" | "XMLTABLE" | "XMLTEXT" | "XMLVALIDATE"
		| "ZONE"
		{ addToken(Token.RESERVED_WORD); }

		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
			-- below is FUNCTIONS, which is marked in that section
			-- datatypes: "BIT" | "BLOB" | "BOOLEAN" | "CHAR" | "CHARACTER" | "CLOB" | "DATE" | "DEC" | "DECIMAL" | "FLOAT" | "INT" | "INTEGER" | "NCHAR" | "NCLOB" | "NUMERIC" | "REAL" | "SMALLINT" | "TIME" | "TIMESTAMP" |  | "VARCHAR" | "VARIABLE"
			-- functions: "CURRENT_CATALOG" | "CURRENT_PATH" | "CURRENT_ROLE" | "CURRENT_SCHEMA" | "DAY" | "HOUR" | "LOCALTIME" | "LOCALTIMESTAMP" | "MINUTE" | "MONTH" | "PERCENTILE_CONT" | "PERCENTILE_DISC" | "PERCENT_RANK" | "SECOND" | "STDDEV_POP" | "STDDEV_SAMP" | "TIMEZONE_HOUR" | "TIMEZONE_MINUTE" | "VAR_POP" | "VAR_SAMP" | "YEAR"
		 *------------------------------------------------*/

	/*================================================
	** ANSI SQL reserved words
	**================================================*/
		"absolute" | "action" | "allocate" | "are" | "assertion" |
		"bit_length" | "both" |
		"cascaded" | "case" | "cast" | "catalog" | "character" | "character_length" | "collate" | "collation" | "column" | "connection" | "constraints" | "corresponding" | "cross" | 
		"dec" | "deferrable" | "deferred" | "describe" | "descriptor" | "diagnostics" | "disconnect" | "domain" |
		"end-exec" | "exception" | "extract" |
		"false" | "first" | "found" | "full" |
		"get" | "global" |
		"immediate" | "indicator" | "initially" | "inner" | "input" | "insensitive" | "interval" |
		"join" |
		"language" | "last" | "leading" | "left" | "local" | "lower" |
		"match" | "module" |
		"names" | "natural" | "next" | "no" |
		"octet_length" | "outer" | "output" | "overlaps" |
		"pad" | "partial" | "position" | "preserve" | "prior" |
		"relative" | "restrict" | "right" |
		"scroll" | "section" | "semi_sensitive" | "size " | "space" | "sql" | "sqlcode" | "sqlerror" | "sqlstate" | 
		"then" | "trailing" | "translate" | "translation" | "true" |
		"unknown" | "usage" |
		"value" |
		"when" | "whenever" | "write" |
		"zone"
		{ addToken(Token.RESERVED_WORD); }
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
			-- well, 'go' is normaly a isql "send" command, so we dont want it in here
			"go" | 
			-- below is DATATYPES, which is marked in that section
			"bit" | 
			"char" | 
			"date" | "decimal" | 
			"float" | 
			"int" | "integer" | 
			"nchar" | "numeric" | 
			"real" | 
			"smallint" | 
			"time" | "timestamp" | 
			"varchar" | 
			-- below is FUNCTIONS, which is marked in that section
			"char_length" | "coalesce" | "current_date" | "current_time" | 
			"day" | 
			"month" | 
			"nullif" | 
			"substring" | 
			"upper" | 
			"year" | 
			"current_timestamp" | "current_user" |
			"hour" | "minute" | "second" | "session_user " | "system_user" | "timezone_hour" | "timezone_minute" | "trim" | 
		 *------------------------------------------------*/

	/*================================================
	** Potential ANSI SQL reserved words
	**================================================*/
		"after" | "alias" | "async" |
		"before" | "breadth" |
		"call" | "completion" | "cycle" |
		"data" | "depth" | "dictionary" |
		"each" | "elseif" | "equals" |
		"general" |
		"ignore" |
		"leave" | "less" | "limit" | "loop" |
		"modify" |
		"new" | "none" |
		"object" | "oid" | "old" | "operation" | "operators" | "others" |
		"parameters" | "pendant" | "preorder" | "private" | "protected" |
		"recursive" | "ref" | "referencing" | "resignal" | "return" | "returns" | "routine" | "row" |
		"savepoint" | "search" | "sensitive" | "sequence" | "signal" | "similar" | "sqlexception" | "structure" |
		"test" | "there" | "type" |
		"under" |
		"variable" | "virtual" | "visible" |
		"wait" | "without"
		{ addToken(Token.RESERVED_WORD); }

		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
		 	-- "boolean" | 
		 *------------------------------------------------*/

	/*================================================
	** Microsoft SQL-Server datatypes
	**================================================*/
		/* -- Exact numerics */
		"bigint" | "bit" | "decimal" | "int" | "money" | "numeric" | "smallint" | "smallmoney" | "tinyint"   { addToken(Token.DATA_TYPE); }

		/* -- Approximate numerics */
		"float" | "real"   { addToken(Token.DATA_TYPE); }
		
		/* -- Date and time */
		"date" | "datetime2" | "datetime" | "datetimeoffset" | "smalldatetime" | "time"   { addToken(Token.DATA_TYPE); }

		/* -- Character strings */
		"char" | "varchar" | "text"   { addToken(Token.DATA_TYPE); }
		
		/* -- Unicode character strings */
		"nchar" | "nvarchar" | "ntext"  { addToken(Token.DATA_TYPE); }
		
		/* -- Binary strings */
		"binary" | "varbinary" | "image"   { addToken(Token.DATA_TYPE); }
		
		/* -- Other data types */
		"cursor" | "hierarchyid" | "sql_variant" | "table" | "rowversion" | "uniqueidentifier" | "xml" | "geometry" | "geography"   { addToken(Token.DATA_TYPE); }

		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
		 	-- NONE
		 *------------------------------------------------*/

	/*================================================
	** Microsoft Transact-SQL FUNCTIONS
	**================================================*/
		/* -- ODBC Functions */
		 "BIT_LENGTH" | "CONCAT" | "OCTET_LENGTH" | "TRUNCATE" | "CURRENT_DATE" | "CURDATE" | "CURRENT_TIME" | "CURTIME" | "DAYNAME" | "DAYOFMONTH" | "DAYOFWEEK" | "HOUR" | "MINUTE" | "SECOND" | "MONTHNAME" | "QUARTER" | "WEEK" { addToken(Token.FUNCTION); }

		/* -- Aggregate Functions */
		 "APPROX_COUNT_DISTINCT" | "AVG" | "CHECKSUM_AGG" | "COUNT" | "COUNT_BIG" | "GROUPING" | "GROUPING_ID" | "MAX" | "MIN" | "STDEV" | "STDEVP" | "STRING_AGG" | "SUM" | "VAR" | "VARP" { addToken(Token.FUNCTION); }

		/* -- Analytic Functions  */
		 "CUME_DIST" | "FIRST_VALUE" | "LAG" | "LAST_VALUE" | "LEAD" | "PERCENTILE_CONT" | "PERCENTILE_DISC" | "PERCENT_RANK" { addToken(Token.FUNCTION); }

		/* -- Collation Functions */
		 "COLLATIONPROPERTY" | "TERTIARY_WEIGHTS" { addToken(Token.FUNCTION); }

		/* -- Conversion Functions  */
		 "CAST" | "CONVERT" | "PARSE" | "TRY_CAST" | "TRY_CONVERT" | "TRY_PARSE" { addToken(Token.FUNCTION); }
		 
		/* -- Cryptographic functions */
		 "ENCRYPTBYKEY" | "ENCRYPTBYPASSPHRASE" | "KEY_ID" | "DECRYPTBYKEYAUTOASYMKEY" | "SYMKEYPROPERTY" | "DECRYPTBYKEY" | "DECRYPTBYPASSPHRASE" | "KEY_GUID" | "KEY_NAME" | "ENCRYPTBYASYMKEY" | "ENCRYPTBYCERT" | "ASYMKEYPROPERTY" | "DECRYPTBYASYMKEY" | "DECRYPTBYCERT" | "ASYMKEY_ID" | "SIGNBYASYMKEY"| "SIGNBYCERT" | "IS_OBJECTSIGNED" | "VERIFYSIGNEDBYASMKEY" | "VERIGYSIGNEDBYCERT" | "DecryptByKeyAutoCert" | "HASHBYTES" | "CERTENCODED" | "CERTPRIVATEKEY" { addToken(Token.FUNCTION); }

		/* -- Cursor  */
		 "CURSOR_STATUS" { addToken(Token.FUNCTION); }

		/* -- Data type */
		 "DATALENGTH" | "IDENT_CURRENT" | "IDENT_INCR" | "IDENT_SEED" | "IDENTITY" | "SQL_VARIANT_PROPERTY" { addToken(Token.FUNCTION); }

		/* -- Date and Time Data Types and Functions */
		 "SYSDATETIME" | "SYSDATETIMEOFFSET" | "SYSUTCDATETIME" | "CURRENT_TIMESTAMP" | "GETDATE" | "GETUTCDATE" | "DATENAME" | "DATEPART" | "DAY" | "MONTH" | "YEAR" | "DATEFROMPARTS" | "DATETIME2FROMPARTS" | "DATETIMEFROMPARTS" | "DATETIMEOFFSETFROMPARTS" | "SMALLDATETIMEFROMPARTS" | "TIMEFROMPARTS" | "DATEDIFF" | "DATEDIFF_BIG" | "DATEADD" | "EOMONTH" | "SWITCHOFFSET" | "TODATETIMEOFFSET" | "ISDATE" { addToken(Token.FUNCTION); }

		/* -- JSON */
		 "ISJSON" | "JSON_VALUE" | "JSON_QUERY" | "JSON_MODIFY" | "OPENJSON" { addToken(Token.FUNCTION); }

		/* -- Mathematical Functions */
		 "ABS" | "ACOS" | "ASIN" | "ATAN" | "ATN2" | "CEILING" | "COS" | "COT" | "DEGREES" | "EXP" | "FLOOR" | "LOG" | "LOG10" | "PI" | "POWER" | "RADIANS" | "RAND" | "ROUND" | "SIGN" | "SIN" | "SQRT" | "SQUARE" | "TAN" { addToken(Token.FUNCTION); }

		/* -- Logical Functions */
		 "CHOOSE" | "IIF" { addToken(Token.FUNCTION); }

		/* -- Metadata */
		 "APP_NAME" | "APPLOCK_MODE" | "APPLOCK_TEST" | "ASSEMBLYPROPERTY" | "COL_LENGTH" | "COL_NAME" | "COLUMNPROPERTY" | "DATABASE_PRINCIPAL_ID" | "DATABASEPROPERTYEX" | "DB_ID" | "DB_NAME" | "FILE_ID" | "FILE_IDEX" | "FILE_NAME" | "FILEGROUP_ID" | "FILEGROUP_NAME" | "FILEGROUPPROPERTY" | "FILEPROPERTY" | "FULLTEXTCATALOGPROPERTY" | "FULLTEXTSERVICEPROPERTY" | "INDEX_COL" | "INDEXKEY_PROPERTY" | "INDEXPROPERTY" | "NEXT VALUE FOR" | "OBJECT_DEFINITION" | "OBJECT_ID" | "OBJECT_NAME" | "OBJECT_SCHEMA_NAME" | "OBJECTPROPERTY" | "OBJECTPROPERTYEX" | "ORIGINAL_DB_NAME" | "PARSENAME" | "SCHEMA_ID" | "SCHEMA_NAME" | "SCOPE_IDENTITY" | "SERVERPROPERTY" | "STATS_DATE" | "TYPE_ID" | "TYPE_NAME" | "TYPEPROPERTY" | "VERSION" { addToken(Token.FUNCTION); }

		/* -- Ranking Functions  */
		 "RANK" | "DENSE_RANK" | "NTILE" | "ROW_NUMBER" { addToken(Token.FUNCTION); }

		/* -- Replication Functions */
		 "PUBLISHINGSERVERNAME" { addToken(Token.FUNCTION); }

		/* -- Rowset */
		 "OPENDATASOURCE" | "OPENJSON" | "OPENQUERY" | "OPENROWSET" | "OPENXML" { addToken(Token.FUNCTION); }

		/* -- Security */
		 "CERTENCODED" | "CERTPRIVATEKEY" | "CURRENT_USER" | "DATABASE_PRINCIPAL_ID" | "fn_builtin_permissions" | "fn_get_audit_file" | "fn_my_permissions" | "HAS_PERMS_BY_NAME" | "IS_MEMBER" | "IS_ROLEMEMBER" | "IS_SRVROLEMEMBER" | "ORIGINAL_LOGIN" | "PWDCOMPARE" | "PWDENCRYPT" | "SCHEMA_ID" | "SCHEMA_NAME" | "SESSION_USER" | "SUSER_ID" | "SUSER_SID" | "SUSER_SNAME" | "SYSTEM_USER" | "SUSER_NAME" | "USER_ID" | "USER_NAME" { addToken(Token.FUNCTION); }

		/* -- String */
		 "ASCII" | "CONCAT" | "FORMAT" | "LOWER" | "PATINDEX" | "REPLICATE" | "RTRIM" | "STR" | "STRING_SPLIT" | "TRANSLATE" | "UPPER" | "CHAR" | "CONCAT_WS" | "LEFT" | "LTRIM" | "QUOTENAME" | "REVERSE" | "SOUNDEX" | "STRING_AGG" | "STUFF" | "TRIM" | "CHARINDEX" | "DIFFERENCE" | "LEN" | "NCHAR" | "REPLACE" | "RIGHT" | "SPACE" | "STRING_ESCAPE" | "SUBSTRING" | "UNICODE" { addToken(Token.FUNCTION); }

		/* -- System */
		 "$PARTITION" | "BINARY_CHECKSUM" | "CHECKSUM" | "COMPRESS" | "CONNECTIONPROPERTY" | "CONTEXT_INFO" | "CURRENT_REQUEST_ID" | "CURRENT_TRANSACTION_ID" | "DECOMPRESS" | "ERROR_LINE" | "ERROR_MESSAGE" | "ERROR_NUMBER" | "ERROR_PROCEDURE" | "ERROR_SEVERITY" | "ERROR_STATE" | "FORMATMESSAGE" | "GET_FILESTREAM_TRANSACTION_CONTEXT" | "GETANSINULL" | "HOST_ID" | "HOST_NAME" | "ISNULL" | "ISNUMERIC" | "MIN_ACTIVE_ROWVERSION" | "NEWID" | "NEWSEQUENTIALID" | "ROWCOUNT_BIG" | "SESSION_CONTEXT" | "SESSION_ID" | "XACT_STATE" { addToken(Token.FUNCTION); }

		/* -- System Statistical */
		 "fn_virtualfilestats" { addToken(Token.FUNCTION); }

		/* -- Text & Image */
		 "TEXTPTR" | "TEXTVALID" { addToken(Token.FUNCTION); }

		/* -- Trigger Functions */
		 "COLUMNS_UPDATED" | "EVENTDATA" | "TRIGGER_NESTLEVEL" | "UPDATE" { addToken(Token.FUNCTION); }

	/*================================================
	** Extra FUNCTIONS added by Goran Schwarz
	**================================================*/
		"COALESCE" | "NULLIF" | "TSEQUAL"
		{ addToken(Token.FUNCTION); }


	/*================================================
	** Microsoft Transact-SQL Global variables
	**================================================*/
		"@@CONNECTIONS" | "@@CPU_BUSY" | "@@CURSOR_ROWS" 
		| "@@DATEFIRST" | "@@DBTS" 
		| "@@ERROR" 
		| "@@FETCH_STATUS" 
		| "@@IDLE" | "@@IO_BUSY" | "@@IDENTITY" 
		| "@@LANGID" | "@@LANGUAGE" | "@@LOCK_TIMEOUT" 
		| "@@MAX_CONNECTIONS" | "@@MAX_PRECISION" 
		| "@@NESTLEVEL" 
		| "@@OPTIONS" 
		| "@@PACKET_ERRORS" | "@@PACK_RECEIVED" | "@@PACK_SENT" | "@@PROCID" 
		| "@@REMSERVER" | "@@ROWCOUNT" 
		| "@@SERVERNAME" | "@@SERVICENAME" | "@@SPID" 
		| "@@TRANCOUNT" | "@@TEXTSIZE" | "@@TIMETICKS" | "@@TOTAL_ERRORS" | "@@TOTAL_READ" | "@@TOTAL_WRITE" 
		| "@@VERSION" 
		{ addToken(Token.VARIABLE); }

		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
		 	-- NONE
		 *------------------------------------------------*/

	{LineTerminator}			{ addNullToken(); return firstToken; }

	{Identifier}				{ addToken(Token.IDENTIFIER); }
	";"							{ addToken(Token.IDENTIFIER); }
	{Variable}					{ addToken(Token.VARIABLE); }
/*	{GlobalVariable}			{ addToken(Token.VARIABLE); }*/

	{Parameter}					{ addToken(Token.IDENTIFIER); }

	{Comment}					{ addToken(Token.COMMENT_EOL); }
	{MLCBegin}					{ start = zzMarkedPos-2; yybegin(MLC); }

	{Whitespace}				{ addToken(Token.WHITESPACE); }

	{Operator}					{ addToken(Token.OPERATOR); }
	{Separator}					{ addToken(Token.SEPARATOR); }

	{Integer}					{ addToken(Token.LITERAL_NUMBER_DECIMAL_INT); }
	{Float}						{ addToken(Token.LITERAL_NUMBER_FLOAT); }
	{ApproxNum}					{ addToken(Token.LITERAL_NUMBER_FLOAT); }

	"\""						{ start = zzMarkedPos-1; yybegin(STRING); }
	"\'"						{ start = zzMarkedPos-1; yybegin(CHAR); }

	"["[^\]]*"]"				{ addToken(Token.PREPROCESSOR); }
	"["[^\]]*					{ addToken(Token.ERROR_IDENTIFIER); addNullToken(); return firstToken; }

	<<EOF>>						{ addNullToken(); return firstToken; }

	/* Catch any other (unhandled) characters and flag them as OK; */
	/* I don't know enough about SQL to know what's really invalid. */
	.							{ addToken(Token.IDENTIFIER); }

}

<STRING> {

	[^\n\"]+			{}
	\n					{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }
	"\"\""				{}
	"\""				{ yybegin(YYINITIAL); addToken(start,zzStartRead, Token.LITERAL_STRING_DOUBLE_QUOTE); }
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }

}

<CHAR> {

	[^\n\']+			{}
	\n					{ addToken(start,zzStartRead-1, Token.LITERAL_CHAR); return firstToken; }
	"\'\'"				{}
	"\'"				{ yybegin(YYINITIAL); addToken(start,zzStartRead, Token.LITERAL_CHAR); }
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.LITERAL_CHAR); return firstToken; }

}

<MLC> {

	[^\n\*]+			{}
	\n					{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }
	{MLCEnd}			{ yybegin(YYINITIAL); addToken(start,zzStartRead+1, Token.COMMENT_MULTILINE); }
	\*					{}
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }

}
