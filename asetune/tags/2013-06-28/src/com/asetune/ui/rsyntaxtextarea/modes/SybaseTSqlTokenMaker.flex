/*
 * 2012-11-07
 *
 * SybaseTSqlTokenMaker.java - Scanner for SQL.
 *
 * Copyright (C) 2012 Goran Schwarz
 * Copyright (C) 2005 Robert Futrell
 * robert_futrell at users.sourceforge.net
 * http://fifesoft.com/rsyntaxtextarea
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA.
 */
package com.asetune.ui.rsyntaxtextarea.modes;

import java.io.*;
import javax.swing.text.Segment;

import org.fife.ui.rsyntaxtextarea.*;


/**
 * This class generates tokens representing a text stream as SQL.<p>
 *
 * This implementation was created using
 * <a href="http://www.jflex.de/">JFlex</a> 1.4.1; however, the generated file
 * was modified for performance.  Memory allocation needs to be almost
 * completely removed to be competitive with the handwritten lexers (subclasses
 * of <code>AbstractTokenMaker</code>, so this class has been modified so that
 * Strings are never allocated (via yytext()), and the scanner never has to
 * worry about refilling its buffer (needlessly copying chars around).
 * We can achieve this because RText always scans exactly 1 line of tokens at a
 * time, and hands the scanner this line as an array of characters (a Segment
 * really).  Since tokens contain pointers to char arrays instead of Strings
 * holding their contents, there is no need for allocating new memory for
 * Strings.<p>
 *
 * The actual algorithm generated for scanning has, of course, not been
 * modified.<p>
 *
 * If you wish to regenerate this file yourself, keep in mind the following:
 * <ul>
 *   <li>The generated SQLTokenMaker.java</code> file will contain two
 *       definitions of both <code>zzRefill</code> and <code>yyreset</code>.
 *       You should hand-delete the second of each definition (the ones
 *       generated by the lexer), as these generated methods modify the input
 *       buffer, which we'll never have to do.</li>
 *   <li>You should also change the declaration/definition of zzBuffer to NOT
 *       be initialized.  This is a needless memory allocation for us since we
 *       will be pointing the array somewhere else anyway.</li>
 *   <li>You should NOT call <code>yylex()</code> on the generated scanner
 *       directly; rather, you should use <code>getTokenList</code> as you would
 *       with any other <code>TokenMaker</code> instance.</li>
 * </ul>
 *
 * @author Robert Futrell
 * @version 0.5
 *
 */
%%

%public
%class SybaseTSqlTokenMaker
%extends AbstractJFlexTokenMaker
%unicode
%ignorecase
%type org.fife.ui.rsyntaxtextarea.Token


%{


	/**
	 * Constructor.  This must be here because JFlex does not generate a
	 * no-parameter constructor.
	 */
	public SybaseTSqlTokenMaker() {
		super();
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 */
	private void addToken(int tokenType) {
		addToken(zzStartRead, zzMarkedPos-1, tokenType);
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 */
	private void addToken(int start, int end, int tokenType) {
		int so = start + offsetShift;
		addToken(zzBuffer, start,end, tokenType, so);
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param array The character array.
	 * @param start The starting offset in the array.
	 * @param end The ending offset in the array.
	 * @param tokenType The token's type.
	 * @param startOffset The offset in the document at which this token
	 *                    occurs.
	 */
	public void addToken(char[] array, int start, int end, int tokenType, int startOffset) {
		super.addToken(array, start,end, tokenType, startOffset);
		zzStartRead = zzMarkedPos;
	}


	/**
	 * Returns the text to place at the beginning and end of a
	 * line to "comment" it in a this programming language.
	 *
	 * @return The start and end strings to add to a line to "comment"
	 *         it out.
	 */
	public String[] getLineCommentStartAndEnd() {
		return new String[] { "--", null };
	}


	/**
	 * Returns the first token in the linked list of tokens generated
	 * from <code>text</code>.  This method must be implemented by
	 * subclasses so they can correctly implement syntax highlighting.
	 *
	 * @param text The text from which to get tokens.
	 * @param initialTokenType The token type we should start with.
	 * @param startOffset The offset into the document at which
	 *        <code>text</code> starts.
	 * @return The first <code>Token</code> in a linked list representing
	 *         the syntax highlighted text.
	 */
	public Token getTokenList(Segment text, int initialTokenType, int startOffset) {

		resetTokenList();
		this.offsetShift = -text.offset + startOffset;

		// Start off in the proper state.
		int state = Token.NULL;
		switch (initialTokenType) {
			case Token.LITERAL_STRING_DOUBLE_QUOTE:
				state = STRING;
				start = text.offset;
				break;
			case Token.LITERAL_CHAR:
				state = CHAR;
				start = text.offset;
				break;
			case Token.COMMENT_MULTILINE:
				state = MLC;
				start = text.offset;
				break;
			default:
				state = Token.NULL;
		}

		s = text;
		try {
			yyreset(zzReader);
			yybegin(state);
			return yylex();
		} catch (IOException ioe) {
			ioe.printStackTrace();
			return new DefaultToken();
		}

	}


	/**
	 * Refills the input buffer.
	 *
	 * @return      <code>true</code> if EOF was reached, otherwise
	 *              <code>false</code>.
	 */
	private boolean zzRefill() {
		return zzCurrentPos>=s.offset+s.count;
	}


	/**
	 * Resets the scanner to read from a new input stream.
	 * Does not close the old reader.
	 *
	 * All internal variables are reset, the old input stream 
	 * <b>cannot</b> be reused (internal buffer is discarded and lost).
	 * Lexical state is set to <tt>YY_INITIAL</tt>.
	 *
	 * @param reader   the new input stream 
	 */
	public final void yyreset(java.io.Reader reader) {
		// 's' has been updated.
		zzBuffer = s.array;
		/*
		 * We replaced the line below with the two below it because zzRefill
		 * no longer "refills" the buffer (since the way we do it, it's always
		 * "full" the first time through, since it points to the segment's
		 * array).  So, we assign zzEndRead here.
		 */
		//zzStartRead = zzEndRead = s.offset;
		zzStartRead = s.offset;
		zzEndRead = zzStartRead + s.count - 1;
		zzCurrentPos = zzMarkedPos = zzPushbackPos = s.offset;
		zzLexicalState = YYINITIAL;
		zzReader = reader;
		zzAtBOL  = true;
		zzAtEOF  = false;
	}


%}

LineTerminator		= ([\n])
Letter			= ([A-Za-z])
Digit			= ([0-9])
Whitespace		= ([ \t]+)

IdentifierStart	= ({Letter})
IdentifierPart		= ({IdentifierStart}|{Digit}|[_])
Identifier		= ({IdentifierStart}{IdentifierPart}*)
Variable		= (@{Identifier})
/*GlobalVariable	= (@@{Identifier})*/

Operator			= (">="|"<="|"<>"|">"|"<"|"="|"+"|"-"|"*"|"/")
Separator			= ([\(\)])

Parameter			= ([:]{Identifier})

Integer			= ({Digit}+)
Float			= (({Digit}+[.]{Digit}*)|([.]{Digit}*))
ApproxNum			= (({Digit}+[eE][+-]?{Digit}+)|({Digit}+[.]{Digit}*[eE][+-]?[0-9]+)|([.][0-9]*[eE][+-]?[0-9]+))

CommentBegin		= ("--")
Comment			= ({CommentBegin}.*)
MLCBegin			= "/*"
MLCEnd			= "*/"

%state STRING
%state CHAR
%state MLC

%%

<YYINITIAL> {

	/* Keywords */

	/*================================================
	** Transact-SQL reserved words
	**================================================*/
		"add" | "all" | "alter" | "and" | "any" | "arith_overflow" | "as" | "asc" | "at" | "authorization" | 
		"begin" | "between" | "break" | "browse" | "bulk" | "by" |
		"cascade" | "case" | "char_convert" | "check" | "checkpoint" | "close" | "clustered" | "commit" | "compressed" | "compute" | "confirm" | "connect" | "constraint" | "continue" | "controlrow" | "create" | "current" | "cursor" |
		"database" | "dbcc" | "deallocate" | "declare" | "decrypt" | "default" | "delete" | "desc" | "deterministic" | "disk" | "distinct" | "drop" | "dual_control" | "dummy" | "dump" |
		"else" | "encrypt" | "end" | "endtran" | "errlvl" | "errordata" | "errorexit" | "escape" | "except" | "exclusive" | "exec" | "execute" | "exists" | "exit" | "exp_row_size" | "external" |
		"fetch" | "fillfactor" | "for" | "foreign" | "from" |
		"goto" | "grant" | "group" |
		"having" | "holdlock" |
		"identity" | "identity_gap" | "identity_start" | "if" | "in" | "index" | "inout" | "insensitive" | "insert" | "install" | "intersect" | "into" | "is" | "isolation" |
		"jar" | "join" |
		"key" | "kill" |
		"level" | "like" | "lineno" | "load" | "lob_compression" | "lock" |
		"materialized" | "max_rows_per_page" | "mirror" | "mirrorexit" | "modify" |
		"national" | "new" | "noholdlock" | "nonclustered" | "not" | "null" | "numeric_truncation" |
		"of" | "off" | "offsets" | "on" | "once" | "online" | "only" | "open" | "option" | "or" | "order" | "out" | "output" | "over" |
		"partition" | "perm" | "permanent" | "plan" | "prepare" | "primary" | "print" | "privileges" | "proc" | "procedure" | "processexit" | "proxy_table" | "public" |
		"quiesce" |
		"raiserror" | "read" | "readpast" | "readtext" | "reconfigure" | "references" | "release_locks_on_close" | "remove" | "reorg" | "replace" | "replication" | "reservepagegap" | "return" | "returns" | "revoke" | "role" | "rollback" | "rowcount" | "rows" | "rule" |
		"save" | "schema" | "scroll" | "select" | "semi_sensitive" | "set" | "setuser" | "shared" | "shutdown" | "some" | "statistics" | "stringsize" | "stripe" | "syb_identity" | "syb_restree" | "syb_terminate" |
		"table" | "temp" | "temporary" | "textsize" | "to" | "tracefile" | "tran" | "transaction" | "trigger" | "truncate" | 
		"union" | "unique" | "unpartition" | "update" | "use" | "user_option" | "using" |
		"values" | "varying" | "view" |
		"waitfor" | "when" | "where" | "while" | "with" | "work" | "writetext" 
	{ addToken(Token.RESERVED_WORD); }
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
			-- below is FUNCTIONS, which is marked in that section
			"avg" | 
			"coalesce" | "count" | "count_big" | 
			"convert" | 
			"max" | "min" | 
			"nullif" | 
			"sum" | 
			"tsequal" | 
			"user" | 
			"xmlextract" | "xmlparse" | "xmltest" | 
		 *------------------------------------------------*/

	/*================================================
	** ANSI SQL reserved words
	**================================================*/
		"absolute" | "action" | "allocate" | "are" | "assertion" |
		"bit_length" | "both" |
		"cascaded" | "case" | "cast" | "catalog" | "character" | "character_length" | "collate" | "collation" | "column" | "connection" | "constraints" | "corresponding" | "cross" | "current_timestamp" | "current_user" |
		"dec" | "deferrable" | "deferred" | "describe" | "descriptor" | "diagnostics" | "disconnect" | "domain" |
		"end-exec" | "exception" | "extract" |
		"false" | "first" | "found" | "full" |
		"get" | "global" |
		"hour" |
		"immediate" | "indicator" | "initially" | "inner" | "input" | "insensitive" | "interval" |
		"join" |
		"language" | "last" | "leading" | "left" | "local" | "lower" |
		"match" | "minute" | "module" |
		"names" | "natural" | "next" | "no" |
		"octet_length" | "outer" | "output" | "overlaps" |
		"pad" | "partial" | "position" | "preserve" | "prior" |
		"relative" | "restrict" | "right" |
		"scroll" | "second" | "section" | "semi_sensitive" | "session_user " | "size " | "space" | "sql" | "sqlcode" | "sqlerror" | "sqlstate" | "system_user" |
		"then" | "timezone_hour" | "timezone_minute" | "trailing" | "translate" | "translation" | "trim" | "true" |
		"unknown" | "usage" |
		"value" |
		"when" | "whenever" | "write" |
		"zone"
	{ addToken(Token.RESERVED_WORD); }
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
			-- well, 'go' is normaly a isql "send" command, so we dont want it in here
			"go" | 
			-- below is DATATYPES, which is marked in that section
			"bit" | 
			"char" | 
			"date" | "decimal" | 
			"float" | 
			"int" | "integer" | 
			"nchar" | "numeric" | 
			"real" | 
			"smallint" | 
			"time" | "timestamp" | 
			"varchar" | 
			-- below is FUNCTIONS, which is marked in that section
			"char_length" | "coalesce" | "current_date" | "current_time" | 
			"day" | 
			"month" | 
			"nullif" | 
			"substring" | 
			"upper" | 
			"year" | 
		 *------------------------------------------------*/

	/*================================================
	** Potential ANSI SQL reserved words
	**================================================*/
		"after" | "alias" | "async" |
		"before" | "boolean" | "breadth" |
		"call" | "completion" | "cycle" |
		"data" | "depth" | "dictionary" |
		"each" | "elseif" | "equals" |
		"general" |
		"ignore" |
		"leave" | "less" | "limit" | "loop" |
		"modify" |
		"new" | "none" |
		"object" | "oid" | "old" | "operation" | "operators" | "others" |
		"parameters" | "pendant" | "preorder" | "private" | "protected" |
		"recursive" | "ref" | "referencing" | "resignal" | "return" | "returns" | "routine" | "row" |
		"savepoint" | "search" | "sensitive" | "sequence" | "signal" | "similar" | "sqlexception" | "structure" |
		"test" | "there" | "type" |
		"under" |
		"variable" | "virtual" | "visible" |
		"wait" | "without"
	{ addToken(Token.RESERVED_WORD); }
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
		 	-- NONE
		 *------------------------------------------------*/

	/*================================================
	** Sybase datatypes
	**================================================*/
		"unsigned" | "bigint" | "int" | "integer" | "smallint" | "tinyint" |
		"numeric" | "decimal" | "float" | "double" | "precision" | "real" |
		"smallmoney" | "money" | "smalldatetime" |
		"datetime" | "date" | "time" | "bigdatetime" | "bigtime" |
		"char" | "varchar" | "unichar" | "univarchar" | "nchar" | "nvarchar" |
		"text" |"unitext" |
		"binary" | "varbinary" |
		"image" |
		"bit" |
		"sysname" | "longsysname" | "timestamp"			
	{ addToken(Token.DATA_TYPE); }
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
		 	-- NONE
		 *------------------------------------------------*/

	/*================================================
	** Sybase functions
	**================================================*/
		"abs" | "acos" | "ascii" | "asehostname" | "asin" | "atan" | "atn2" | "avg" | "audit_event_name" | "authmech" | 
		"biginttohex" | "bintostr" | 
		"cache_usage" | "case" | "cast" | "ceiling" | "char" | "char_length" | "charindex" | "coalesce" | "col_length" | "col_name" | "compare" | "convert" | "cos" | "cot" | "count" | "count_big" | "create_locator" | "current_bigdatetime" | "current_bigtime" | "current_date" | "current_time" | "curunreservedpgs" | "data_pages" | 
		"datachange" | "datalength" | "dateadd" | "datediff" | "datename" | "datepart" | "day" | "db_attr" | "db_id" | "db_instanceid" | "db_name" | "db_recovery_status" | "degrees" | "derived_stat" | "difference" | "dol_downgrade_check" | 
		"exp" | 
		"floor" | 
		"get_appcontext" | "getdate" | "get_internal_date" | "getutcdate" | 
		"has_role" | "hash" | "hashbytes" | "hextobigint" | "hextoint" | "host_id" | "host_name" | 
		"instance_id" | "identity_burn_max" | "index_col" | "index_colorder" | "index_name" | "inttohex" | "isdate" | "is_quiesced" | "is_sec_service_on" | "is_singleusermode" | "isnull" | "isnumeric" | "instance_name" | 
		"lc_id" | "lc_name" | "lct_admin" | "left" | "len" | "license_enabled" | "list_appcontext" | "locator_literal" | "locator_valid" | "lockscheme" | "log" | "log10" | "lower" | "lprofile_id" | "lprofile_name" | "ltrim" | 
		"max" | "migrate_instance_id" | "min" | "month" | "mut_excl_roles" | "newid" | 
		"next_identity" | "nullif" | 
		"object_attr" | "object_id" | "object_name" | "object_owner_id" | 
		"pagesize" | "partition_id" | "partition_name" | "partition_object_id" | "password_random" | "patindex" | "pi" | "power" | "proc_role" | "pssinfo" | 
		"radians" | "rand" | "rand2" | "replicate" | "reserve_identity" | "reserved_pages" | "return_lob" | "reverse" | "right" | "rm_appcontext" | "role_contain" | "role_id" | "role_name" | "round" | "row_count" | "rtrim" | 
		"sdc_intempdbconfig" | "set_appcontext" | "setdata" | "show_cached_plan_in_xml" | "show_cached_text" | "show_cached_text_long" | "show_dynamic_params_in_xml" | "show_plan" | "show_role" | "show_sec_services" | "sign" | "sin" | "sortkey" | "soundex" | "space" | "spid_instance_id" | "square" | "sqrt" | "stddev" | "stdev" | "stdevp" | "stddev_pop" | "stddev_samp" | "str" | "str_replace" | "strtobin" | "stuff" | "substring" | "sum" | "suser_id" | "suser_name" | "syb_quit" | "syb_sendmsg" | "sys_tempdbid" | 
		"tan" | "tempdb_id" | "textptr" | "textvalid" | "to_unichar" | "tran_dumpable_status" | "tsequal" | 
		"uhighsurr" | "ulowsurr" | "upper" | "uscalar" | "used_pages" | "user" | "user_id" | "user_name" | 
		"valid_name" | "valid_user" | "var" | "var_pop" | "var_samp" | "variance" | "varp" | 
		"workload_metric" | 
		"xa_bqual" | "xa_gtrid" | "xact_connmigrate_check" | "xact_owner_instance" | "xmlextract" | "xmlparse" | "xmlrepresentation" | "xmltable" | "xmltest" | "xmlvalidate" | 
		"year"
	{ addToken(Token.FUNCTION); }
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
		 	-- NONE
		 *------------------------------------------------*/

	/*================================================
	** Sybase GLOABAL VARIABLES
	**================================================*/
		"@@active_instances" | "@@authmech" | 
		"@@bootcount" | "@@boottime" | "@@bulkarraysize" | "@@bulkbatchsize" | 
		"@@char_convert" | "@@cis_rpc_handling" | "@@cis_version" | "@@client_csexpansion" | "@@client_csid" | "@@client_csname" | "@@clusterboottime" | "@@clustercoordid" | "@@clustermode" | "@@clustername" | "@@cmpstate" | "@@connections" | "@@cpu_busy" | "@@cursor_rows" | "@@curloid" | 
		"@@datefirst" | "@@dbts" | 
		"@@error" | "@@errorlog" | 
		"@@failedoverconn" | "@@fetch_status" | 
		"@@guestuserid" | 
		"@@hacmpservername" | "@@haconnection" | "@@heapmemsize" | 
		"@@identity" | "@@idle" | "@@instanceid" | "@@instancename" | "@@invaliduserid" | "@@io_busy" | "@@isolation" | 
		"@@jsinstanceid" | 
		"@@kernel_addr" | "@@kernel_size" | "@@kernelmode" | 
		"@@langid" | "@@language" | "@@lastkpgendate" | "@@lastlogindate" | "@@lock_timeout" | "@@lwpid" | 
		"@@max_connections" | "@@max_precision" | "@@maxcharlen" | "@@maxgroupid" | "@@maxpagesize" | "@@maxspid" | "@@maxsuid" | "@@maxuserid" | "@@mempool_addr" | "@@min_poolsize" | "@@mingroupid" | "@@minspid" | "@@minsuid" | "@@minuserid" | "@@monitors_active" | 
		"@@ncharsize" | "@@nestlevel" | "@@nextkpgendate" | "@@nodeid" | 
		"@@optgoal" | "@@optoptions" | "@@options" | "@@optlevel" | "@@opttimeoutlimit" | "@@ospid" | 
		"@@pack_received" | "@@pack_sent" | "@@packet_errors" | "@@pagesize" | "@@parallel_degree" | "@@plwpid" | "@@probesuid" | "@@procid" | 
		"@@quorum_physname" | 
		"@@recovery_state" | "@@remotestate" | "@@repartition_degree" | "@@resource_granularity" | "@@rowcount" | 
		"@@scan_parallel_degree" | "@@servername" | "@@setrowcount" | "@@shmem_flags" | "@@spid" | "@@sqlstatus" | "@@ssl_ciphersuite" | "@@stringsize" | "@@sys_tempdbid" | "@@system_busy" | "@@system_view" | 
		"@@tempdbid" | "@@textcolid" | "@@textdataptnid" | "@@textdbid" | "@@textobjid" | "@@textptnid" | "@@textptr" | "@@textptr_parameters" | "@@textsize" | "@@textts" | "@@thresh_hysteresis" | "@@timeticks" | "@@total_errors" | "@@total_read" | "@@total_write" | "@@tranchained" | "@@trancount" | "@@transactional_rpc" | "@@transtate" | 
		"@@unicharsize" | "@@user_busy" | 
		"@@version" | "@@version_as_integer" | "@@version_number"
	{ addToken(Token.VARIABLE); }
		/*------------------------------------------------
		 * removed values from the above
		 *------------------------------------------------
		 	-- NONE
		 *------------------------------------------------*/

	{LineTerminator}				{ addNullToken(); return firstToken; }

	{Identifier}					{ addToken(Token.IDENTIFIER); }
/*	";"							{ addToken(Token.IDENTIFIER); }*/
	{Variable}					{ addToken(Token.VARIABLE); }
/*	{GlobalVariable}				{ addToken(Token.VARIABLE); }*/

	{Parameter}					{ addToken(Token.IDENTIFIER); }

	{Comment}						{ addToken(Token.COMMENT_EOL); }
	{MLCBegin}					{ start = zzMarkedPos-2; yybegin(MLC); }

	{Whitespace}					{ addToken(Token.WHITESPACE); }

	{Operator}					{ addToken(Token.OPERATOR); }
	{Separator}					{ addToken(Token.SEPARATOR); }

	{Integer}						{ addToken(Token.LITERAL_NUMBER_DECIMAL_INT); }
	{Float}						{ addToken(Token.LITERAL_NUMBER_FLOAT); }
	{ApproxNum}					{ addToken(Token.LITERAL_NUMBER_FLOAT); }

	"\""							{ start = zzMarkedPos-1; yybegin(STRING); }
	"\'"							{ start = zzMarkedPos-1; yybegin(CHAR); }

	"["[^\]]*"]"					{ addToken(Token.PREPROCESSOR); }
	"["[^\]]*						{ addToken(Token.ERROR_IDENTIFIER); addNullToken(); return firstToken; }

	<<EOF>>						{ addNullToken(); return firstToken; }

	/* Catch any other (unhandled) characters and flag them as OK; */
	/* I don't know enough about SQL to know what's really invalid. */
	.							{ addToken(Token.IDENTIFIER); }

}

<STRING> {

	[^\n\"]+				{}
	\n					{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }
	"\"\""				{}
	"\""					{ yybegin(YYINITIAL); addToken(start,zzStartRead, Token.LITERAL_STRING_DOUBLE_QUOTE); }
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }

}

<CHAR> {

	[^\n\']+				{}
	\n					{ addToken(start,zzStartRead-1, Token.LITERAL_CHAR); return firstToken; }
	"\'\'"				{}
	"\'"					{ yybegin(YYINITIAL); addToken(start,zzStartRead, Token.LITERAL_CHAR); }
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.LITERAL_CHAR); return firstToken; }

}

<MLC> {

	[^\n\*]+				{}
	\n					{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }
	{MLCEnd}				{ yybegin(YYINITIAL); addToken(start,zzStartRead+1, Token.COMMENT_MULTILINE); }
	\*					{}
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }

}
